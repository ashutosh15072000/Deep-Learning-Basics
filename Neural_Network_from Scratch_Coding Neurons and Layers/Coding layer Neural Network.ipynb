{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `BUILDING NEURAL NETWORKS FROM SCRATCH PART 1: CODING NEURONS AND LAYERS`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>CODING OUR FIRST NEURON: 3 INPUTS</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](IMG/nueron_with_3_inputs.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n"
     ]
    }
   ],
   "source": [
    "inputs=[1,2,3]\n",
    "wieghts=[0.2,0.8,-0.5]\n",
    "bais=2\n",
    "\n",
    "output=(inputs[0]*wieghts[0]+inputs[1]*wieghts[1]+inputs[2]*wieghts[2]+bais)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "SINGLE NEURON USING NUMPY\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](IMG/single_neuron_with_numpy.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "Inputs=[1.0,2.0,3.0,2.5]\n",
    "Weights=[0.2,0.8,-0.5,1.0]\n",
    "bais=2.0\n",
    "output=np.dot(Inputs,Weights)+bais\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>CODING OUR SECOND NEURON: 4 INPUTS</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](IMG/nueron_with_4_inputs.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "inputs=[1.0,2.0,3.0,2.5]\n",
    "weights=[0.2,0.8,-0.5,1.0]\n",
    "bais=2.0\n",
    "output=(inputs[0]*weights[0]+\n",
    "        inputs[1]*weights[1]+\n",
    "        inputs[2]*weights[2]+\n",
    "        inputs[3]*weights[3]+\n",
    "        bais)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>CODING OUR FIRST LAYER</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](IMG/Layer_of_neuron.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1],\n",
    " [0.5, -0.91, 0.26, -0.5],\n",
    " [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "weights1 = weights[0] #LIST OF WEIGHTS ASSOCIATED WITH 1ST NEURON : W11, W12, W13, W14\n",
    "weights2 = weights[1] #LIST OF WEIGHTS ASSOCIATED WITH 2ND NEURON : W21, W22, W23, W24\n",
    "weights3 = weights[2] #LIST OF WEIGHTS ASSOCIATED WITH 3RD NEURON : W31, W32, W33, W34\n",
    "\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "bias1 = 2\n",
    "bias2 = 3\n",
    "bias3 = 0.5\n",
    "\n",
    "outputs = [\n",
    " # Neuron 1:\n",
    " inputs[0]*weights1[0] +\n",
    " inputs[1]*weights1[1] +\n",
    " inputs[2]*weights1[2] +\n",
    " inputs[3]*weights1[3] + bias1,\n",
    " # Neuron 2:\n",
    " inputs[0]*weights2[0] +\n",
    " inputs[1]*weights2[1] +\n",
    " inputs[2]*weights2[2] +\n",
    " inputs[3]*weights2[3] + bias2,\n",
    " # Neuron 3:\n",
    " inputs[0]*weights3[0] +\n",
    " inputs[1]*weights3[1] +\n",
    " inputs[2]*weights3[2] +\n",
    " inputs[3]*weights3[3] + bias3]\n",
    "\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "USING LOOPS FOR BETTER AND EASIER CODING</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 6.01, 8.395]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "\n",
    "##LIST OF WEIGHTS\n",
    "weights = [[0.2, 0.8, -0.5, 1],\n",
    " [0.5, -0.91, 0.26, -0.5],\n",
    " [-0.26, -0.27, 0.17, 0.87]]\n",
    "\n",
    "##LIST OF BIASES\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "# Output of current layer\n",
    "neuron_output = 0\n",
    "layer_outputs=[]\n",
    "# For each neuron\n",
    "for neuron_weights, neuron_bias in zip(weights, biases):\n",
    "    for weight,n_inputs in zip(neuron_weights,inputs):\n",
    "         # Multiply this input by associated weight\n",
    "         # and add to the neuron's output variable\n",
    "        neuron_output += n_inputs*weight ## W31*X1 + W32*X2 + W33*X3 + W34*X4\n",
    "   # Add bias\n",
    "    neuron_output += neuron_bias ## ## W31*X1 + W32*X2 + W33*X3 + W34*X4 + B3\n",
    "\n",
    "    layer_outputs.append(neuron_output)    \n",
    "print(layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "LAYER OF NEURONS USING NUMPY\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](<IMG/Screenshot 2024-10-25 152610.jpg>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8   1.21  2.385]\n"
     ]
    }
   ],
   "source": [
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "weights = [[0.2, 0.8, -0.5, 1],\n",
    " [0.5, -0.91, 0.26, -0.5],\n",
    " [-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2.0, 3.0, 0.5]\n",
    "\n",
    "# A dot product of a matrix and a vector results in a list of dot products. \n",
    "#The np.dot() method treats the matrix as a list of vectors and performs a dot product of each of those vectors with the other vector\n",
    "layer_outputs = np.dot(weights, inputs) + biases\n",
    "print(layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "LAYER OF NEURONS AND BATCH OF DATA USING NUMPY\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](IMG/Batch_of_inputs.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "NEED TO TAKE TRANSPOSE OF WEIGHT MATRIX</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](IMG/transpose_of.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "## Batch of Inputs\n",
    "inputs=[[1.0,2.0,3.0,2.5],\n",
    "        [2.0,5.0,-1.0,2.0],\n",
    "        [-1.5,2.7,3.3,-0.8]]\n",
    "weights=[[0.2,0.8,-0.5,1],\n",
    "         [0.5,-0.91,0.26,-0.5],\n",
    "         [-0.26,-0.27,0.17,0.87]]\n",
    "bais=[2.0,3.0,0.5]\n",
    "# NOTE: We cant Transpose Lists in python so we have the convert the weights matrix into array first\n",
    "outputs=np.dot(inputs,np.array(weights).T)+bais\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "2 LAYERS AND BATCH OF DATA USING NUMPY\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](IMG/Two_layers.jpg)\n",
    "![alt text](IMG/weight_of_two_layer.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5031  -1.04185 -2.03875]\n",
      " [ 0.2434  -2.7332  -5.7633 ]\n",
      " [-0.99314  1.41254 -0.35655]]\n"
     ]
    }
   ],
   "source": [
    "## Batch of Inputs\n",
    "inputs=[[1.0,2.0,3.0,2.5],\n",
    "        [2.0,5.0,-1.0,2.0],\n",
    "        [-1.5,2.7,3.3,-0.8]]\n",
    "## First Layers Weights\n",
    "weights=[[0.2,0.8,-0.5,1],\n",
    "         [0.5,-0.91,0.26,-0.5],\n",
    "         [-0.26,-0.27,0.17,0.87]]\n",
    "\n",
    "baise1=[2,3,0.5]\n",
    "\n",
    "## Second Layers Weights\n",
    "weights2=[[0.1,-0.14,0.5],\n",
    "          [-0.5,0.12,-0.33],\n",
    "          [-0.44,0.73,-0.13]\n",
    "        ]\n",
    "bais2=[-1,2,-0.5]\n",
    "\n",
    "## Convert lists to numpy array\n",
    "inputs_array=np.array(inputs)\n",
    "weights_array=np.array(weights)\n",
    "bais_array=np.array(baise1)\n",
    "weight2_array=np.array(weights2)\n",
    "baises2_array=np.array(bais2)\n",
    "\n",
    "## CALCULATE THE OUTPUT FOR FIRST LAYER:\n",
    "layer1_outputs=np.dot(inputs,weights_array.T)+bais_array\n",
    "\n",
    "## CALUCLATE THE OUTPUT FOR SECOND LAYER\n",
    "layer2_outputs=np.dot(layer1_outputs,weight2_array.T)+baises2_array\n",
    "\n",
    "print(layer2_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>DENSE LAYER CLASS</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](IMG/class.jpg)\n",
    "![alt text](<IMG/Class dense laywe.jpg>)\n",
    "![alt text](<IMG/Initializing weights.jpg>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
      " [-1.0475188e-04  1.1395361e-04 -4.7983500e-05]\n",
      " [-2.7414842e-04  3.1729150e-04 -8.6921798e-05]\n",
      " [-4.2188365e-04  5.2666257e-04 -5.5912682e-05]\n",
      " [-5.7707680e-04  7.1401405e-04 -8.9430439e-05]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data\n",
    "nnfs.init()\n",
    "\n",
    "#DENSE LAYER:\n",
    "class Layer_Dense:\n",
    "    #LAYER INITIALIZATION\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        #INITIALIZE WEIGHT AND BIASES\n",
    "        self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    #FORWARD PASS\n",
    "    def forward(self, inputs):\n",
    "        #CALUCLATE OUTPUT VALUES FROM INPUTS,WEIGHTS AND BIASES\n",
    "        self.output=np.dot(inputs,self.weights)+self.biases\n",
    "#CREATE DATASET\n",
    "X, y = spiral_data(samples=100, classes=3)\n",
    "#CREATE DENSE LAYER WITH 2 INPUT FEATURES AND # OUTPUT VALUES\n",
    "dense_layer1 = Layer_Dense(2, 3)\n",
    "# PERFORM a FORWARD PASS of OUR TRAINING DATA THROUGH THIS LAYER\n",
    "dense_layer1.forward(X)\n",
    "# LET'S SEE THE OUTPUT OF THE FIRST SAMPLES:\n",
    "print(dense_layer1.output[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Activation Function :Relu</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](IMG/Activation_functions.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  2.  0.  3.3 0.  1.1 2.2 0. ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "inputs=[0,2,-1,3.3,-2.7,1.1,2.2,-100]\n",
    "output=np.maximum(0,inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relu Activation\n",
    "class Activation_Relu:\n",
    "    ## Forward Pass\n",
    "    def forward(self, inputs):\n",
    "        self.output=np.maximum(0,inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Activation Function :Softmax</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](IMG/softmax.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1\n",
    "![Step 1](<IMG/Screenshot 2024-10-27 101702.jpg>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13533528, 0.36787944, 1.        , 0.60653066],\n",
       "       [0.04978707, 1.        , 0.00247875, 0.04978707],\n",
       "       [0.00822975, 0.54881164, 1.        , 0.01657268]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SETP 1\n",
    "exp_values=np.exp(inputs-np.max(inputs,axis=1,keepdims=True))\n",
    "exp_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2\n",
    "![alt text](<IMG/Screenshot 2024-10-27 100913.jpg>)\n",
    "![alt text](IMG/softmax_probalties.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.06414769, 0.17437149, 0.47399085, 0.28748998],\n",
       "       [0.04517666, 0.90739747, 0.00224921, 0.04517666],\n",
       "       [0.00522984, 0.34875873, 0.63547983, 0.0105316 ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## STEP 2\n",
    "probabilities=exp_values/np.sum(exp_values,axis=1,keepdims=True)\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.06414769 0.17437149 0.47399085 0.28748998]\n",
      " [0.04517666 0.90739747 0.00224921 0.04517666]\n",
      " [0.00522984 0.34875873 0.63547983 0.0105316 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Activation Softmax\n",
    "## Activation softmax is a common activation function used in the output layer of a neural network. It is used\n",
    "## to output a probability distribution over the classes. The softmax function is defined as follows:\n",
    "inputs=[[1,2,3,2.5],\n",
    "        [2.,5.,-1.,2],\n",
    "        [-1.5,2.7,3.3,-0.8]]\n",
    "## get unnormalized probabiltites\n",
    "exp_values=np.exp(inputs-np.max(inputs,axis=1,keepdims=True))\n",
    "## normalize them for each sample\n",
    "probabilities=exp_values/np.sum(exp_values,axis=1,keepdims=True)\n",
    "print(probabilities)\n",
    "np.sum(probabilities,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax Activation Fucntion\n",
    "class Activation_Softmax:\n",
    "    # FORWARD PASS\n",
    "    def forward(self,inputs):\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values=np.exp(inputs-np.max(inputs,axis=1,keepdims=True))\n",
    "        # Normalize them for each sample\n",
    "        probabilities=exp_values/np.sum(exp_values,axis=1,keepdims=True)\n",
    "        self.output=probabilities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>FORWARD PASS</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](IMG/forward_pass.jpg)\n",
    "![alt text](IMG/simplicztion_forward_pass.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333334 0.33333334 0.33333334]\n",
      " [0.33333334 0.33333334 0.33333334]\n",
      " [0.33333334 0.33333334 0.33333334]\n",
      " [0.33333334 0.33333334 0.33333334]\n",
      " [0.33333334 0.33333334 0.33333334]]\n"
     ]
    }
   ],
   "source": [
    "# CREATE DATASET\n",
    "X,y=spiral_data(samples=100,classes=3)\n",
    "# CREATE DENSE LAYER WITH INPUT FEATURES AND  OUTPUT VALUES\n",
    "\n",
    "dense1=Layer_Dense(2,3)\n",
    "# CREATE RELU ACTIVATION FUNCTION(TO BE USED WITH DENSE LAYER)\n",
    "\n",
    "activation1=Activation_Relu()\n",
    "\n",
    "# CREATE DENSE LAYER WITH OUTPUT FROM PREVIOUS LAYER AND 1 OUTPUT\n",
    "dense2=Layer_Dense(3,3)\n",
    "\n",
    "# CREATE SOFTMAX ACTIVATION FUNCTION\n",
    "activation2=Activation_Softmax()\n",
    "# MAKE A FORWARD PASS OF OUR TRAINING DATA THROUGH THIS LAYER\n",
    "\n",
    "dense1.forward(X)\n",
    "# MAKE A FORWARD PASS THROUGH ACTIVATION FUNCTION IT TAKES OUTPUT OF FIRST DENSE LAYER HERE\n",
    "\n",
    "activation1.forward(dense1.output)\n",
    "\n",
    "# MAKE A FORWARD PASS THROUGH SECOND DENSE LAYER\n",
    "# IT TAKES FORWARD OUTPUTS OF ACTIVATION FUNCTION OF FIRST LAYER AS INPUTS\n",
    "dense2.forward(activation1.output)\n",
    "\n",
    "# MAKE A FORWARD PASS THROUGH ACTIVATION FUNCTION IT TAKES OUTPUT OF SECOND DENSE LAYER HERE\n",
    "activation2.forward(dense2.output)\n",
    "\n",
    "# SEE THE OUTPUT OF THE FIRST FEW SAMPLES\n",
    "print(activation2.output[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
