{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>GRADIENT LOSS WITH WIEGHTS</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](IMG/gradientwrtweights.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  0.5,  0.5],\n",
       "       [20.1, 20.1, 20.1],\n",
       "       [10.9, 10.9, 10.9],\n",
       "       [ 4.1,  4.1,  4.1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# PASSED IN GRADIENT FROM THE NEXT LAYER\n",
    "# FOR THE PURPOSE OF THIS WE ARE GOING TO USE AN ARRAY OF AN INCREMENTAL GRADIENT VALUES\n",
    "dvalues=np.array([[1.,1.,1.],\n",
    "[2.,2.,2.],\n",
    "[3.,3.,3.]])\n",
    "#WE SET # SETS OF INPUTS SAMPLES\n",
    "inputs=np.array([[1,2,3,2.5],[2.,5.,-1,2],[-1.5,2.7,3.3,-.8]])\n",
    "# SUM WEIGHTS OF GIVEN INPUTS\n",
    "# AND MULTIPLY BY THE PASSED IN GRADIENT FOR THIS NEURON\n",
    "dwieghts=np.dot(inputs.T,dvalues)\n",
    "dwieghts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "GRADIENTS OF THE LOSS WITH RESPECT TO BIASES\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](IMG/gradientwrtbiases.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 6. 6.]]\n"
     ]
    }
   ],
   "source": [
    "# ONE BIAS FOR EACH NEURON\n",
    "# BIASES ARE THE ROW VECTOR WITH A SHAPE (1,NUERONS)\n",
    "biases=np.array([2,3,0.5])\n",
    "# dbiases - sum values do thsi over samples first axis, keepdims\n",
    "# since this default will produce a plain list\n",
    "dbiases=np.sum(dvalues,axis=0,keepdims=True)\n",
    "print(dbiases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "GRADIENTS OF THE LOSS WITH RESPECT TO INPUTS\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](IMG/graidentwrtinput.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.44 -0.38 -0.07  1.37]\n",
      " [ 0.88 -0.76 -0.14  2.74]\n",
      " [ 1.32 -1.14 -0.21  4.11]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Passed-in gradient from the next layer\n",
    "# for the purpose of this example we're going to use\n",
    "# an array of an incremental gradient values\n",
    "dvalues = np.array([[1., 1., 1.],\n",
    " [2., 2., 2.],\n",
    " [3., 3., 3.]])\n",
    "# We have 3 sets of weights - one set for each neuron\n",
    "# we have 4 inputs, thus 4 weights\n",
    "# recall that we keep weights transposed\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    " [0.5, -0.91, 0.26, -0.5],\n",
    " [-0.26, -0.27, 0.17, 0.87]]).T\n",
    "# sum weights of given input\n",
    "# and multiply by the passed-in gradient for this neuron\n",
    "dinputs = np.dot(dvalues, weights.T)\n",
    "print(dinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
